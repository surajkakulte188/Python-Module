{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Statistics Advance Part-1\n",
        "**Theory Question**\n",
        "\n",
        "Q.1 What is a random variable in probability theory?\n",
        "\n",
        "‚Üí In probability theory, a random variable is a numerical quantity whose value is determined by the outcome of a random experiment. A random variable is a function that maps outcomes of a sample space to real numbers.\n",
        "- A random variable turns outcomes of random processes into numbers.\n",
        "- It allows us to apply mathematical tools like probability distributions, expectation & variance to analyze randomness.\n",
        "\n",
        "Q.2 What are the types of random variables?\n",
        "\n",
        "‚Üí In probability theory, a random variable turns outcomes of random processes into numbers. There are two main types of random variables in probability theory:\n",
        "1. Discrete Random Variable:\n",
        "- Takes on countable values (e.g., 0, 1, 2, 3...).\n",
        "- Ex.: Number of heads in 3 coin tosses.\n",
        "2. Continuous Random Variable:\n",
        "- Takes on uncountably infinite values within a range (e.g., all real numbers between 0 & 1).\n",
        "- Ex.: The time it takes for a bus to arrive (could be 3.2 mins, 3.23 mins, etc.).\n",
        "\n",
        "Q.3 What is the difference between discrete and continuous distributions?\n",
        "\n",
        "‚Üí The difference between discrete & continuous distributions are as given:\n",
        "1. Discrete Distribution:\n",
        "- Deals with discrete random variables (countable values).\n",
        "- Probabilities are assigned to specific individual outcomes.\n",
        "- Uses a Probability Mass Function (PMF).\n",
        "- The sum of all probabilities is exactly 1.\n",
        "2. Continuous Distribution:\n",
        "- Deals with continuous random variables (uncountable real values).\n",
        "- Probability is assigned to intervals, not individual values.\n",
        "- Uses a Probability Density Function (PDF).\n",
        "- The total area under the curve is 1.\n",
        "\n",
        "Q.4 What are probability distribution functions (PDF)?\n",
        "\n",
        "‚Üí A Probability Distribution Function (PDF) is a function that describes the likelihood of a continuous random variable taking on a specific value within an interval. The key Points about PDFs:\n",
        "- Used for continuous random variables.\n",
        "- The curve must be non-negative & integrate to 1.\n",
        "- It gives the density of probability, not the exact probability.\n",
        "- P(X = x) = 0 for any exact value ùë•.\n",
        "\n",
        "Q.5 How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?\n",
        "\n",
        "‚Üí\n",
        "1. Probability Distribution Dunctions (PDF):\n",
        "- Applies to: Continuous random variables.\n",
        "- Denotes the density of probability at each point.\n",
        "- Describes the shape of the distribution.\n",
        "- P(X = x) = 0 ‚Üí probability at a specific point is zero.\n",
        "- Ex.: Bell-shaped curve in a Normal distribution.\n",
        "2. Cumulative Distribution Dunctions (CDF):\n",
        "- Applies to both discrete & continuous random variables.\n",
        "- Always increases (never decreases).\n",
        "- Ranges from 0 to 1 as ùë• increases.\n",
        "\n",
        "Q.6 What is a discrete uniform distribution?\n",
        "\n",
        "‚Üí A discrete uniform distribution is a probability distribution where each outcome in a finite set is equally likely. The key Characteristics of discrete uniform distribution are as follow:\n",
        "- The random variable takes on a finite number of discrete values.\n",
        "- All values have the same probability.\n",
        "- Ex.: Rolling a fair six-sided die.\n",
        "\n",
        "Q.7 What are the key properties of a Bernoulli distribution?\n",
        "\n",
        "‚Üí A Bernoulli distribution is the building block of the Binomial distribution, which models the number of successes in multiple Bernoulli trials. If a random variable X follows a Bernoulli distribution with success probability ùëù, we write: X ‚àº Bernoulli(p). A Bernoulli distribution models a single experiment that has exactly two outcomes:\n",
        "- Success (usually denoted as 1).\n",
        "- Failure (usually denoted as 0).\n",
        "\n",
        "Q.8 What is the binomial distribution, and how is it used in probability?\n",
        "\n",
        "‚Üí The binomial distribution is a discrete probability distribution that models the number of successes in a fixed number of independent Bernoulli trials, where each trial has the same probability of success. It is used in probability as follows:\n",
        "- Tossing a coin 10 times & counting the number of heads.\n",
        "- Number of defective items in a batch of 20.\n",
        "- Number of correct answers in a multiple-choice quiz with guessing.\n",
        "- Probability that exactly 3 out of 5 customers buy a product.\n",
        "\n",
        "Q.9 What is the Poisson distribution and where is it applied?\n",
        "\n",
        "‚Üí The Poisson distribution is a discrete probability distribution that models the number of times an event occurs in a fixed interval of time or space, given that the events occur:\n",
        "- Independently.\n",
        "- With a constant average rate Œª (lambda).\n",
        "- The probability of more than one event occurring in an infinitesimally small interval is negligible.\n",
        "\n",
        "Q.10 What is a continuous uniform distribution?\n",
        "\n",
        "‚Üí The continuous uniform distribution is a probability distribution where a continuous random variable is equally likely to take any value within a given interval [a, b]. If a random variable X is uniformly distributed between a & b, we write: X ‚àº Uniform (a,b). Application as given:\n",
        "- Generating random numbers between two values.\n",
        "- Modeling equal probability outcomes within an interval.\n",
        "- Estimating time between two known bounds with no bias.\n",
        "\n",
        "Q.11 What are the characteristics of a normal distribution?\n",
        "\n",
        "‚Üí The normal distribution (also called the Gaussian distribution) is one of the most important probability distributions in statistics and data science. It describes how values of a continuous random variable are distributed in a symmetric, bell-shaped curve. The key characteristics as follows:\n",
        "1. Bell-Shaped Curve\n",
        "2. Defined by Two Parameters\n",
        "3. Probability Density Function (PDF)\n",
        "4. Symmetry\n",
        "5. Mean = Median = Mode\n",
        "6. Empirical Rule (68-95-99.7 Rule)\n",
        "7. Asymptotic\n",
        "8. Total Area Under Curve = 1\n",
        "\n",
        "Q.12 What is the standard normal distribution, and why is it important?\n",
        "\n",
        "‚Üí The standard normal distribution is a special case of the normal distribution with: Mean Œº = 0 & Standard deviation ùúé = 1.\n",
        "- It is denoted as: Z ‚àº N(0,1).\n",
        "- The variable Z is often called the standard score or Z-score.\n",
        "\n",
        "It is important, because of:\n",
        "1. Simplifies Calculations\n",
        "2. Enables Comparisons\n",
        "3. Widely Used in Hypothesis Testing\n",
        "4. Forms the Basis of Many Statistical Methods\n",
        "5. Supports Normal Approximation\n",
        "\n",
        "Q.13 What is the Central Limit Theorem (CLT), and why is it critical in statistics?\n",
        "\n",
        "‚Üí The Central Limit Theorem (CLT) is one of the most fundamental & powerful concepts in statistics. It states:\n",
        "- The distribution of the sample mean (or sum) of a large number of independent & identically distributed (i.i.d.) random variables approaches a normal distribution, regardless of the original distribution of the data. It is critical in statistics, because of:\n",
        "1. Justifies Normal Approximations\n",
        "2. Foundation of Hypothesis Testing & Confidence Intervals\n",
        "3. Works for Most Real-World Data\n",
        "4. Applies to Sums & Averages\n",
        "5. Enables Use of Standard Normal Table (Z-table).\n",
        "\n",
        "Q.14 How does the Central Limit Theorem relate to the normal distribution?\n",
        "\n",
        "‚Üí The Central Limit Theorem (CLT) explains why & when the normal distribution appears in statistics - even when the original data is not normally distributed. The relationship Between CLT & Normal Distribution:\n",
        "- CLT connects arbitrary distributions to the normal distribution through sample means.\n",
        "- Explains why the normal distribution is so commonly used in statistics.\n",
        "- Allows use of standard normal tools (like Z-tests) even when data is not normal, as long as sample size is large.\n",
        "- It makes statistical inference robust & widely applicable.\n",
        "\n",
        "Q.15 What is the application of Z statistics in hypothesis testing?  \n",
        "\n",
        "‚Üí Z-statistics are used in hypothesis testing when the population standard deviation is known & the data is either:\n",
        "- Normally distributed.\n",
        "- Sample size is large (usually n‚â•30) - by the Central Limit Theorem.\n",
        "\n",
        "Key Applications of Z-Statistics in Hypothesis Testing:\n",
        "1. Testing the Population Mean\n",
        "2. Testing Proportions\n",
        "3. Comparing Two Means (Large Samples)\n",
        "4. Comparing Two Proportions.\n",
        "\n",
        "Q.16 How do you calculate a Z-score, and what does it represent?\n",
        "\n",
        "‚Üí A Z-score (also called a standard score) tells you how many standard deviations a data point is from the mean of a distribution. For a data point X, with population mean Œº & standard deviation ùúé, where X = observed value, Œº = population mean & ùúé = population standard deviation.\n",
        "\n",
        "It is represent using:\n",
        "- Z-score of 0: Value is exactly at the mean.\n",
        "- A positive Z-score: Value is above the mean.\n",
        "- A negative Z-score: Value is below the mean.\n",
        "\n",
        "Q.17 What are point estimates and interval estimates in statistics?\n",
        "\n",
        "‚Üí In statistics, both point estimates & interval estimates are methods used to infer unknown population parameters (like mean, proportion, etc.) based on sample data.\n",
        "1. Point Estimates:\n",
        "- A single value used to estimate an unknown population parameter.\n",
        "- Ex.: Sample mean X estimates population mean Œº & Sample proportion ùëù estimates population proportion p.\n",
        "- Easy to calculate, but it does not show uncertainty or confidence in the result.\n",
        "- Used as the center of interval estimates.\n",
        "2. Interval Estimates:\n",
        "- A range of values likely to contain the true population parameter.\n",
        "- Includes a confidence level (e.g., 95%, 99%) to indicate reliability.\n",
        "- Form: Estimate ¬± Margin of Error.\n",
        "- Accounts for sampling variability.\n",
        "- More informative than a single point.\n",
        "\n",
        "Q.18 What is the significance of confidence intervals in statistical analysis?\n",
        "\n",
        "‚Üí A confidence interval (CI) is a fundamental tool in statistics that provides a range of values to estimate an unknown population parameter (like mean or proportion), along with a level of certainty or confidence. The key Significance of Confidence Intervals:\n",
        "1. Estimates Uncertainty: CIs give a range, not just a single value, showing how much the estimate might vary.\n",
        "2. Adds Reliability to Point Estimates: A point estimate alone tells you what you observed, while a CI tells you how sure you are about it.\n",
        "3. Connects to Probability: A 95% confidence interval means: If you took 100 samples, about 95 of them would contain the true parameter.\n",
        "4. Improves Transparency: Reporting a CI shows the range of plausible values, making the results more honest & interpretable.\n",
        "\n",
        "Q.19 What is the relationship between a Z-score and a confidence interval?\n",
        "\n",
        "‚Üí The Z-score & confidence interval are closely related in statistical estimation. Together, they help us define how confident we are that a sample statistic (like a sample mean) estimates the true population parameter. Relationship Between Z-score & Confidence Interval are as given:\n",
        "- A Z-score measures how many standard deviations a value is from the mean.\n",
        "- A confidence interval (CI) gives a range of values within which the true population parameter is likely to fall.\n",
        "- Z-scores are used to build confidence intervals when the population standard deviation is known.\n",
        "- Each confidence level corresponds to a specific Z-score.\n",
        "- The Z-score determines the margin of error around the point estimate.\n",
        "- The area under the standard normal curve between -Z & +Z gives the confidence level.\n",
        "\n",
        "Q.20 How are Z-scores used to compare different distributions?\n",
        "\n",
        "‚Üí Z-scores are incredibly useful for comparing data points from different distributions - especially when those distributions have different means & standard deviations.\n",
        "- They convert values into a common scale, based on standard deviations from the mean.\n",
        "- Higher Z-score = better relative performance within that distribution.\n",
        "- Z = 0 means the value is exactly at the mean.\n",
        "- Positive Z = value is above the mean;\n",
        "Negative Z = value is below the mean.\n",
        "- We are able to compare two Z-scores directly, regardless of the original distribution.\n",
        "- It helps in identifying outliers or unusually high/low values.\n",
        "- It enables percentile comparison using the standard normal (Z) table.\n",
        "\n",
        "Q.21 What are the assumptions for applying the Central Limit Theorem?\n",
        "\n",
        "‚Üí The Central Limit Theorem (CLT) states that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the population's distribution, provided certain assumptions are met. The key assumptions for CLT:\n",
        "1. Independent Observations:\n",
        "- Each data point must be independent of the others.\n",
        "- No hidden relationships between sample elements.\n",
        "2. Identically Distributed Variables:\n",
        "- All observations should come from the same population (i.e., same distribution with common mean & variance).\n",
        "3. Finite Mean & Variance:\n",
        "- The population must have a finite (real) mean Œº & finite variance ùúé¬≤.\n",
        "4. Random Sampling:\n",
        "- The sample must be drawn using a random or representative method to avoid bias.\n",
        "5. Independent Sampling:\n",
        "- If sampling without replacement, the sample size should be less than 10% of the population to ensure independence.\n",
        "\n",
        "Q.22 What is the concept of expected value in a probability distribution?\n",
        "\n",
        "‚Üí The expected value of a random variable is a measure of its central tendency - it represents the average outcome you'd expect in the long run if the experiment were repeated many times. It is the long-run average of a random variable over many trials. It is a weighted average of all possible outcomes, where each outcome is weighted by its probability.\n",
        "\n",
        "It is important, because of:\n",
        "- Used in decision-making under uncertainty.\n",
        "- Helps evaluate risks, rewards & insurance premiums.\n",
        "- Fundamental in economics, statistics, finance &machine learning.\n",
        "\n",
        "Q.23 How does a probability distribution relate to the expected outcome of a random variable?\n",
        "\n",
        "‚Üí A probability distribution describes how likely each outcome of a random variable is. The expected outcome is the average value you would get over many repetitions of the random experiment. Relationship Between a Probability Distribution & the Expected Outcome of a Random Variable as given:\n",
        "- A probability distribution assigns a probability to each possible value a random variable can take.\n",
        "- The expected value (mean) is calculated using the probability distribution.\n",
        "-  Each outcome contributes to the expected value in proportion to its probability.\n",
        "- The more probable an outcome, the greater its impact on the expected value.\n",
        "- Even if an outcome is not the most probable, it may heavily influence the expected value if it has a large magnitude.\n",
        "- The probability distribution defines the shape, while the expected value identifies the center.\n",
        "- Expected value is used to summarize the distribution in a single representative number.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_lWHZ3GNFVqX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRkZeK2uFPLm"
      },
      "outputs": [],
      "source": []
    }
  ]
}